{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Changhyun Lee DSC 275"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def findFiles(path): return glob.glob(path)\n",
    "\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "names = {}\n",
    "languages = []\n",
    "\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "for filename in findFiles('data/names/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    languages.append(category)\n",
    "    lines = readLines(filename)\n",
    "    names[category] = lines\n",
    "\n",
    "n_categories = len(languages)\n",
    "\n",
    "def findName(dict, name):\n",
    "    keys = dict.keys()\n",
    "    for key in keys:\n",
    "        if name in dict[key]:\n",
    "            return key\n",
    "    return ''\n",
    "\n",
    "import torch\n",
    "\n",
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "def letterToTensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "def nameToTensor(name):\n",
    "    tensor = torch.zeros(len(name), 1, n_letters)\n",
    "    for li, letter in enumerate(name):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i.item()\n",
    "    return languages[category_i], category_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of tuples (language, name)\n",
    "\n",
    "listOfTuples = []\n",
    "dictNames = names\n",
    "count = 0\n",
    "def createTuple():\n",
    "    for lang, listname in dictNames.items():\n",
    "        for n in listname:\n",
    "            tupleLangName = (n, lang)\n",
    "            listOfTuples.append(tupleLangName)\n",
    "\n",
    "            \n",
    "createTuple()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for lang, listname in names.items():\n",
    "    for n in listname:\n",
    "        if len(n) > max_len:\n",
    "            max_len = len(n)\n",
    "\n",
    "#\n",
    "# import numpy as np\n",
    "# def maxlength(data):\n",
    "#     index = 0\n",
    "#     for i in len(data):\n",
    "#         if len(data[index][0] < len(data[i][0]))\n",
    "#             index = i\n",
    "# return len(data[index][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def data_out(batch_size, data):\n",
    "    x = []\n",
    "    y = []\n",
    "    num_batches = int(len(data)/batch_size)\n",
    "    indices = np.arange(0, len(data))\n",
    "    np.random.shuffle(indices)  \n",
    "    batches = []\n",
    "    batch_i = []\n",
    "    sample_count = 0\n",
    "    \n",
    "    for index in indices:\n",
    "        sample_count += 1\n",
    "        batch_i.append(data[index])\n",
    "       \n",
    "        if sample_count % batch_size == 0:\n",
    "            batches.append(batch_i)\n",
    "            batch_i = []\n",
    "    \n",
    "    for i in range(len(batches)):\n",
    "        tensor_x = torch.zeros(batch_size, max_len, n_letters)\n",
    "        tensor_y = torch.zeros(batch_size, n_categories, dtype=torch.long)\n",
    "        \n",
    "        for j in range(len(batches[i])):\n",
    "            name_tensor = nameToTensor(batches[i][j][0])\n",
    "            \n",
    "            for k in range(len(name_tensor)):\n",
    "                tensor_x[j][k] = name_tensor[k][0]\n",
    "                \n",
    "            category = batches[i][j][1]\n",
    "            category_tensor = torch.zeros(n_categories, dtype=torch.long)\n",
    "            category_tensor[languages.index(category)] = 1\n",
    "            tensor_y[j] = category_tensor\n",
    "            \n",
    "        x.append(tensor_x)\n",
    "        y.append(tensor_y)\n",
    "        \n",
    "    return x, y\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, inputsize, hiddensize, nlayers, outputsize):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.rnn = nn.RNN(         \n",
    "            input_size = inputsize,\n",
    "            hidden_size = hiddensize,         # number of hidden units\n",
    "            num_layers = nlayers,           # number of layers\n",
    "            batch_first = True       # If your input data is of shape (seq_len, batch_size, features) then you donâ€™t need batch_first=True and your RNN will output a tensor with shape (seq_len, batch.\n",
    "        )\n",
    "        self.out = nn.Linear(hiddensize, n_categories)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        r_out, h = self.rnn(x, None)   # None represents zero initial hidden state\n",
    "        out = self.out(r_out[:, -1, :])\n",
    "        return out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch size: 20074"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 | train loss: 2.8597 | test accuracy: 0.468666\n",
      "Epoch:  2 | train loss: 2.6500 | test accuracy: 0.468666\n",
      "Epoch:  3 | train loss: 2.1861 | test accuracy: 0.468666\n",
      "Epoch:  4 | train loss: 2.0358 | test accuracy: 0.468666\n",
      "Epoch:  5 | train loss: 1.9546 | test accuracy: 0.468666\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rnn = RNN(n_letters, 128, 1, n_categories)\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.005)\n",
    "loss_func = nn.CrossEntropyLoss()                       \n",
    "\n",
    "epochs = 5\n",
    "batch_size = 20074\n",
    "\n",
    "# %% training and testing\n",
    "for epoch in range(1, epochs+1):\n",
    "    bx, by = data_out(batch_size, listOfTuples)\n",
    "   \n",
    "    \n",
    "    for batch in range(len(bx)):\n",
    "        x = bx[batch]\n",
    "        y = by[batch]\n",
    "        \n",
    "        output = rnn(x)                                 # rnn output\n",
    "        loss = loss_func(output, torch.max(y, 1)[1])    # cross entropy loss\n",
    "        optimizer.zero_grad()                           # clear gradients for this training step\n",
    "        loss.backward()                                 # backpropagation, compute gradients\n",
    "        optimizer.step()                                # apply gradients\n",
    "\n",
    "    acc_output = rnn(x)                                 # (samples, time_step, input_size)\n",
    "    pred_y = torch.max(acc_output, 1)[1].data.numpy().squeeze()\n",
    "    target = torch.max(y, 1)[1].data.numpy().squeeze()\n",
    "    accuracy = sum(pred_y == target) / y.size(0)\n",
    "\n",
    "    print(\"Epoch: \", epoch, \"| train loss: %.4f\" % loss.item(), '| test accuracy: %.6f' % accuracy)\n",
    "      \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import random\n",
    "\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "def randomTrainingExample():\n",
    "    category = randomChoice(languages)\n",
    "    name = randomChoice(names[category])\n",
    "    category_tensor = torch.tensor([languages.index(category)], dtype=torch.long)\n",
    "    name_tensor = nameToTensor(name)\n",
    "    return category, name, category_tensor, name_tensor\n",
    "\n",
    "# Keep track of correct guesses in a confusion matrix\n",
    "confusion = torch.zeros(n_categories, n_categories)\n",
    "n_confusion = 20074\n",
    "\n",
    "# return an output given an input name\n",
    "def evaluate(name_tensor):\n",
    "#    hidden = rnn.initHidden()\n",
    "    output = rnn(name_tensor)[-1]\n",
    "#    for i in range(name_tensor.size()[0]):\n",
    "#        output, hidden = rnn(name_tensor[i], hidden)\n",
    "\n",
    "    return output\n",
    "\n",
    "def get_accuracy(conf, n_conf, languages, names):\n",
    "    count_correct = 0\n",
    "    \n",
    "    for lang in languages:\n",
    "        for name in names[lang]:\n",
    "            name_tensor = nameToTensor(name)\n",
    "            output = evaluate(name_tensor)\n",
    "            guess, guess_i = categoryFromOutput(output)\n",
    "            \n",
    "            if guess == lang:\n",
    "                count_correct += 1\n",
    "                \n",
    "            category_i = languages.index(lang)\n",
    "            conf[category_i][guess_i] += 1\n",
    "    \n",
    "    return count_correct/n_conf, conf\n",
    "\n",
    "acc = get_accuracy(confusion, n_confusion, languages, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46866593603666434"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
