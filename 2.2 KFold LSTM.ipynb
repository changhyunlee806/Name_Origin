{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 KFold LSTM implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:  1  | Epoch:  1 | train loss: 1.9089 | test accuracy: 0.462000\n",
      "Fold:  1  | Epoch:  2 | train loss: 1.7752 | test accuracy: 0.503000\n",
      "Fold:  1  | Epoch:  3 | train loss: 1.8073 | test accuracy: 0.474000\n",
      "Fold:  1  | Epoch:  4 | train loss: 1.9098 | test accuracy: 0.461000\n",
      "Fold:  1  | Epoch:  5 | train loss: 1.8841 | test accuracy: 0.475000\n",
      "Fold:  2  | Epoch:  1 | train loss: 1.8851 | test accuracy: 0.456000\n",
      "Fold:  2  | Epoch:  2 | train loss: 1.9103 | test accuracy: 0.448000\n",
      "Fold:  2  | Epoch:  3 | train loss: 1.8077 | test accuracy: 0.502000\n",
      "Fold:  2  | Epoch:  4 | train loss: 1.7753 | test accuracy: 0.499000\n",
      "Fold:  2  | Epoch:  5 | train loss: 1.8400 | test accuracy: 0.465000\n",
      "Fold:  3  | Epoch:  1 | train loss: 1.8183 | test accuracy: 0.470000\n",
      "Fold:  3  | Epoch:  2 | train loss: 1.8647 | test accuracy: 0.471000\n",
      "Fold:  3  | Epoch:  3 | train loss: 1.8893 | test accuracy: 0.461000\n",
      "Fold:  3  | Epoch:  4 | train loss: 1.8473 | test accuracy: 0.472000\n",
      "Fold:  3  | Epoch:  5 | train loss: 1.9036 | test accuracy: 0.458000\n",
      "Fold:  4  | Epoch:  1 | train loss: 1.8923 | test accuracy: 0.470000\n",
      "Fold:  4  | Epoch:  2 | train loss: 1.8176 | test accuracy: 0.490000\n",
      "Fold:  4  | Epoch:  3 | train loss: 1.7525 | test accuracy: 0.533000\n",
      "Fold:  4  | Epoch:  4 | train loss: 1.5904 | test accuracy: 0.582000\n",
      "Fold:  4  | Epoch:  5 | train loss: 1.4512 | test accuracy: 0.571000\n",
      "Fold:  5  | Epoch:  1 | train loss: 1.5293 | test accuracy: 0.550000\n",
      "Fold:  5  | Epoch:  2 | train loss: 1.4057 | test accuracy: 0.572000\n",
      "Fold:  5  | Epoch:  3 | train loss: 1.3759 | test accuracy: 0.597000\n",
      "Fold:  5  | Epoch:  4 | train loss: 1.4188 | test accuracy: 0.589000\n",
      "Fold:  5  | Epoch:  5 | train loss: 1.2522 | test accuracy: 0.643000\n",
      "0.4506326591611039\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Dec 14 18:49:13 2019\n",
    "\n",
    "@author: changhyunlee\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def findFiles(path): return glob.glob(path)\n",
    "\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "names = {}\n",
    "languages = []\n",
    "\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "for filename in findFiles('data/names/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    languages.append(category)\n",
    "    lines = readLines(filename)\n",
    "    names[category] = lines\n",
    "\n",
    "n_categories = len(languages)\n",
    "\n",
    "def findName(dict, name):\n",
    "    keys = dict.keys()\n",
    "    for key in keys:\n",
    "        if name in dict[key]:\n",
    "            return key\n",
    "    return ''\n",
    "\n",
    "import torch\n",
    "\n",
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "def letterToTensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "def nameToTensor(name):\n",
    "    tensor = torch.zeros(len(name), 1, n_letters)\n",
    "    for li, letter in enumerate(name):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i.item()\n",
    "    return languages[category_i], category_i\n",
    "\n",
    "# create a list of tuples (language, name)\n",
    "\n",
    "listOfTuples = []\n",
    "dictNames = names\n",
    "count = 0\n",
    "def createTuple():\n",
    "    for lang, listname in dictNames.items():\n",
    "        for n in listname:\n",
    "            tupleLangName = (n, lang)\n",
    "            listOfTuples.append(tupleLangName)\n",
    "\n",
    "            \n",
    "createTuple()\n",
    "#%%\n",
    "\n",
    "#print(names)\n",
    "#%%\n",
    "# kfold\n",
    "import numpy as np \n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#prepare cross-validation\n",
    "kfold = KFold(5, True, 1)\n",
    "\n",
    "kTest = []\n",
    "kTrain = []\n",
    "list1 = []\n",
    "list2 = []\n",
    "list3 = []\n",
    "list4 = []\n",
    "list5 = []\n",
    "\n",
    "list10 = []\n",
    "list20 = []\n",
    "list30 = []\n",
    "list40 = []\n",
    "list50 = []\n",
    "\n",
    "count = 0\n",
    "#enumerate splits\n",
    "#for train, test in kfold.split(listOfTuples):\n",
    "#    print(len(train))\n",
    "    \n",
    "#print()\n",
    "\n",
    "for train, test in kfold.split(listOfTuples):\n",
    "    if count == 0:\n",
    "        for j in test:\n",
    "            list10.append(listOfTuples[j])\n",
    "        kTest.append(list10)\n",
    "        for i in train:\n",
    "            list1.append(listOfTuples[i])\n",
    "        kTrain.append(list1) \n",
    "        count += 1\n",
    "    if count == 1:\n",
    "        for j in test:\n",
    "            list20.append(listOfTuples[j])\n",
    "        kTest.append(list20)\n",
    "        for i in train:\n",
    "            list2.append(listOfTuples[i])\n",
    "        kTrain.append(list2) \n",
    "        count += 1\n",
    "    if count == 2:\n",
    "        for j in test:\n",
    "            list30.append(listOfTuples[j])\n",
    "        kTest.append(list30)\n",
    "        for i in train:\n",
    "            list3.append(listOfTuples[i])\n",
    "        kTrain.append(list3) \n",
    "        count += 1\n",
    "    if count == 3:\n",
    "        for j in test:\n",
    "            list40.append(listOfTuples[j])\n",
    "        kTest.append(list40)\n",
    "        for i in train:\n",
    "            list4.append(listOfTuples[i])\n",
    "        kTrain.append(list4) \n",
    "        count += 1\n",
    "    if count == 4:\n",
    "        for j in test:\n",
    "            list50.append(listOfTuples[j])\n",
    "        kTest.append(list50)\n",
    "        for i in train:\n",
    "            list5.append(listOfTuples[i])\n",
    "        kTrain.append(list5) \n",
    "        count += 1\n",
    "#\tprint(listOfTuples[n])\n",
    "#print(len(list6))\n",
    "#print(kTrain[4])\n",
    "#print(list1[0][1])\n",
    "\n",
    "\n",
    "#%% method to find max length name\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def max(src):\n",
    "    index = 0\n",
    "    for i in range(len(src)):\n",
    "        if len(src[index][0]) < len(src[i][0]):\n",
    "            index = i\n",
    "    return len(src[index][0])\n",
    "\n",
    "\n",
    "def data_out(batch_size, data):\n",
    "    x = []\n",
    "    y = []\n",
    "    num_batches = int(len(data)/batch_size)\n",
    "    indices = np.arange(0, len(data))\n",
    "    np.random.shuffle(indices)  \n",
    "    batches = []\n",
    "    batch_i = []\n",
    "    sample_count = 0\n",
    "    \n",
    "    for index in indices:\n",
    "        sample_count += 1\n",
    "        batch_i.append(data[index])\n",
    "       \n",
    "        if sample_count % batch_size == 0:\n",
    "            batches.append(batch_i)\n",
    "            batch_i = []\n",
    "    \n",
    "    for i in range(len(batches)):\n",
    "        max_len = max(batches[i])\n",
    "        tensor_x = torch.zeros(batch_size, max_len, n_letters)\n",
    "        tensor_y = torch.zeros(batch_size, n_categories, dtype=torch.long)\n",
    "        \n",
    "        for j in range(len(batches[i])):\n",
    "            name_tensor = nameToTensor(batches[i][j][0])\n",
    "            \n",
    "            for k in range(len(name_tensor)):\n",
    "                tensor_x[j][k] = name_tensor[k][0]\n",
    "                \n",
    "            category = batches[i][j][1]\n",
    "            category_tensor = torch.zeros(n_categories, dtype=torch.long)\n",
    "            category_tensor[languages.index(category)] = 1\n",
    "            tensor_y[j] = category_tensor\n",
    "            \n",
    "        x.append(tensor_x)\n",
    "        y.append(tensor_y)\n",
    "        \n",
    "    return x, y\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, inputsize, hiddensize, nlayers, outputsize):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.rnn = nn.LSTM(         \n",
    "            input_size = inputsize,\n",
    "            hidden_size = hiddensize,         # number of hidden units\n",
    "            num_layers = nlayers,           # number of layers\n",
    "            batch_first = True       # If your input data is of shape (seq_len, batch_size, features) then you donâ€™t need batch_first=True and your RNN will output a tensor with shape (seq_len, batch.\n",
    "        )\n",
    "        self.out = nn.Linear(128, n_categories)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        r_out, h = self.rnn(x, None)   # None represents zero initial hidden state\n",
    "        out = self.out(r_out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "\n",
    "\n",
    "rnn = RNN(n_letters, 128, 1, n_categories)\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.005)\n",
    "loss_func = nn.CrossEntropyLoss()                       \n",
    "\n",
    "epochs = 5\n",
    "batch_size = 1000\n",
    "\n",
    "# %% training and testing\n",
    "for i in range(len(kTrain)):\n",
    "    for epoch in range(1, epochs+1):\n",
    "        bx, by = data_out(batch_size, kTrain[i])\n",
    "\n",
    "\n",
    "        for batch in range(len(bx)):\n",
    "            x = bx[batch]\n",
    "            y = by[batch]\n",
    "\n",
    "            output = rnn(x)                                 # rnn output\n",
    "            loss = loss_func(output, torch.max(y, 1)[1])    # cross entropy loss\n",
    "            optimizer.zero_grad()                           # clear gradients for this training step\n",
    "            loss.backward()                                 # backpropagation, compute gradients\n",
    "            optimizer.step()                                # apply gradients\n",
    "\n",
    "        acc_output = rnn(x)                   # (samples, time_step, input_size)\n",
    "        pred_y = torch.max(acc_output, 1)[1].data.numpy().squeeze()\n",
    "        target = torch.max(y, 1)[1].data.numpy().squeeze()\n",
    "        accuracy = sum(pred_y == target) / y.size(0)\n",
    "\n",
    "        print(\"Fold: \", i+1, \" | Epoch: \", epoch, \"| train loss: %.4f\" % loss.item(), '| test accuracy: %.6f' % accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "import random\n",
    "\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "def randomTrainingExample():\n",
    "    category = randomChoice(languages)\n",
    "    name = randomChoice(names[category])\n",
    "    category_tensor = torch.tensor([languages.index(category)], dtype=torch.long)\n",
    "    name_tensor = nameToTensor(name)\n",
    "    return category, name, category_tensor, name_tensor\n",
    "\n",
    "# Keep track of correct guesses in a confusion matrix\n",
    "confusion = torch.zeros(n_categories, n_categories)\n",
    "n_confusion = 20074\n",
    "\n",
    "# return an output given an input name\n",
    "def evaluate(name_tensor):\n",
    "#    hidden = rnn.initHidden()\n",
    "    output = rnn(name_tensor)[-1]\n",
    "#    for i in range(name_tensor.size()[0]):\n",
    "#        output, hidden = rnn(name_tensor[i], hidden)\n",
    "\n",
    "    return output\n",
    "\n",
    "def get_accuracy(conf, n_conf, languages, names):\n",
    "    count_correct = 0\n",
    "    \n",
    "    for lang in languages:\n",
    "        for name in names[lang]:\n",
    "            name_tensor = nameToTensor(name)\n",
    "            output = evaluate(name_tensor)\n",
    "            guess, guess_i = categoryFromOutput(output)\n",
    "            \n",
    "            if guess == lang:\n",
    "                count_correct += 1\n",
    "                \n",
    "            category_i = languages.index(lang)\n",
    "            conf[category_i][guess_i] += 1\n",
    "    \n",
    "    return count_correct/n_conf, conf\n",
    "\n",
    "acc = get_accuracy(confusion, n_confusion, languages, names)\n",
    "print(acc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:  1  | Epoch:  1 | train loss: 1.2533 | test accuracy: 0.632000\n",
      "Fold:  1  | Epoch:  2 | train loss: 1.0876 | test accuracy: 0.687000\n",
      "Fold:  1  | Epoch:  3 | train loss: 1.0839 | test accuracy: 0.715000\n",
      "Fold:  1  | Epoch:  4 | train loss: 0.9983 | test accuracy: 0.724000\n",
      "Fold:  1  | Epoch:  5 | train loss: 0.9916 | test accuracy: 0.725000\n",
      "Fold:  2  | Epoch:  1 | train loss: 1.0066 | test accuracy: 0.737000\n",
      "Fold:  2  | Epoch:  2 | train loss: 0.8343 | test accuracy: 0.762000\n",
      "Fold:  2  | Epoch:  3 | train loss: 0.7987 | test accuracy: 0.770000\n",
      "Fold:  2  | Epoch:  4 | train loss: 0.8032 | test accuracy: 0.776000\n",
      "Fold:  2  | Epoch:  5 | train loss: 0.7163 | test accuracy: 0.794000\n",
      "Fold:  3  | Epoch:  1 | train loss: 0.7253 | test accuracy: 0.794000\n",
      "Fold:  3  | Epoch:  2 | train loss: 0.6209 | test accuracy: 0.832000\n",
      "Fold:  3  | Epoch:  3 | train loss: 0.6573 | test accuracy: 0.812000\n",
      "Fold:  3  | Epoch:  4 | train loss: 0.6660 | test accuracy: 0.802000\n",
      "Fold:  3  | Epoch:  5 | train loss: 0.6073 | test accuracy: 0.811000\n",
      "Fold:  4  | Epoch:  1 | train loss: 0.5541 | test accuracy: 0.840000\n",
      "Fold:  4  | Epoch:  2 | train loss: 0.5601 | test accuracy: 0.826000\n",
      "Fold:  4  | Epoch:  3 | train loss: 0.5532 | test accuracy: 0.837000\n",
      "Fold:  4  | Epoch:  4 | train loss: 0.5133 | test accuracy: 0.843000\n",
      "Fold:  4  | Epoch:  5 | train loss: 0.4389 | test accuracy: 0.857000\n",
      "Fold:  5  | Epoch:  1 | train loss: 0.4663 | test accuracy: 0.860000\n",
      "Fold:  5  | Epoch:  2 | train loss: 0.4259 | test accuracy: 0.869000\n",
      "Fold:  5  | Epoch:  3 | train loss: 0.4005 | test accuracy: 0.884000\n",
      "Fold:  5  | Epoch:  4 | train loss: 0.4068 | test accuracy: 0.873000\n",
      "Fold:  5  | Epoch:  5 | train loss: 0.4156 | test accuracy: 0.882000\n",
      "0.40191292218790475\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %% training and testing\n",
    "for i in range(len(kTest)):\n",
    "    for epoch in range(1, epochs+1):\n",
    "        bx, by = data_out(batch_size, kTrain[i])\n",
    "\n",
    "\n",
    "        for batch in range(len(bx)):\n",
    "            x = bx[batch]\n",
    "            y = by[batch]\n",
    "\n",
    "            output = rnn(x)                                 # rnn output\n",
    "            loss = loss_func(output, torch.max(y, 1)[1])    # cross entropy loss\n",
    "            optimizer.zero_grad()                           # clear gradients for this training step\n",
    "            loss.backward()                                 # backpropagation, compute gradients\n",
    "            optimizer.step()                                # apply gradients\n",
    "\n",
    "        acc_output = rnn(x)                   # (samples, time_step, input_size)\n",
    "        pred_y = torch.max(acc_output, 1)[1].data.numpy().squeeze()\n",
    "        target = torch.max(y, 1)[1].data.numpy().squeeze()\n",
    "        accuracy = sum(pred_y == target) / y.size(0)\n",
    "\n",
    "        print(\"Fold: \", i+1, \" | Epoch: \", epoch, \"| train loss: %.4f\" % loss.item(), '| test accuracy: %.6f' % accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "import random\n",
    "\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "def randomTrainingExample():\n",
    "    category = randomChoice(languages)\n",
    "    name = randomChoice(names[category])\n",
    "    category_tensor = torch.tensor([languages.index(category)], dtype=torch.long)\n",
    "    name_tensor = nameToTensor(name)\n",
    "    return category, name, category_tensor, name_tensor\n",
    "\n",
    "# Keep track of correct guesses in a confusion matrix\n",
    "confusion = torch.zeros(n_categories, n_categories)\n",
    "n_confusion = 20074\n",
    "\n",
    "# return an output given an input name\n",
    "def evaluate(name_tensor):\n",
    "#    hidden = rnn.initHidden()\n",
    "    output = rnn(name_tensor)[-1]\n",
    "#    for i in range(name_tensor.size()[0]):\n",
    "#        output, hidden = rnn(name_tensor[i], hidden)\n",
    "\n",
    "    return output\n",
    "\n",
    "def get_accuracy(conf, n_conf, languages, names):\n",
    "    count_correct = 0\n",
    "    \n",
    "    for lang in languages:\n",
    "        for name in names[lang]:\n",
    "            name_tensor = nameToTensor(name)\n",
    "            output = evaluate(name_tensor)\n",
    "            guess, guess_i = categoryFromOutput(output)\n",
    "            \n",
    "            if guess == lang:\n",
    "                count_correct += 1\n",
    "                \n",
    "            category_i = languages.index(lang)\n",
    "            conf[category_i][guess_i] +=  1\n",
    "    \n",
    "    return count_correct/n_conf, conf\n",
    "\n",
    "acc = get_accuracy(confusion, n_confusion, languages, names)\n",
    "print(acc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
